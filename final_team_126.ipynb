{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j01aH0PR4Sg-"
   },
   "source": [
    "# Project Final\n",
    "Monisha Vatikuti\n",
    "\n",
    "mav12@illinois.edu\n",
    "\n",
    "Team 126\n",
    "\n",
    "Paper 16 - Context-aware Health Event Prediction via Transition Functions on Dynamic Disease Graphs\n",
    "\n",
    "Github Repo: https://github.com/mvattiku/cs598-dlh-project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQ0sNuMePBXx"
   },
   "source": [
    "# Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project's goal is to reproduce the model proposed in the *Context-aware Health Event Prediction via Transition Functions on Dynamic Disease Graphs* (Lu et al. 2022) paper. The paper discusses that the current deep learning models on disease classification and prediction using longitudinal Electronic Health Record (EHR) data treat disease diagnoses as independent events within individual visits. However, in the real-world diseases and symptoms can be interlinked and can reflect hidden patterns in the co-occurrence of disease diagnoses that could be valuable for predicting future patient outcomes. And these patterns are being ignored in current set of models. So the paper proposes a novel deep learning model called Chet (context-aware health event prediction via transition functions on dynamic disease graphs) which looks at both the evolution of diseases and the relationships between diseases to predict future diagnoses. Chet aims to look for interlinked patterns by trying to learn how diseases are progressing over consecutive visits to anticipate future diagnoses.\n",
    "\n",
    "In particular, Chet model learns the evolution of diagnosed diseases across a patient's doctor visits and exploits this learned disease context to forecast future outcomes and diagnoses. The key innovation of this approach lies in its incorporation of both disease co-occurrence information and the dynamic nature of diseases into the model. To accomplish this, the model constructs a weighted disease combination based on the entire longitudinal EHR data globally, as well as a disease subgraph based on the specific visit locally. To account for the dynamic nature of diseases, the paper employs disease-level temporal learning with multiple diagnosis roles and corresponding transition functions to capture historical contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Github Repository\n",
    "https://github.com/mvattiku/cs598-dlh-project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uygL9tTPSVHB"
   },
   "source": [
    "# Scope of Reproducibility:\n",
    "\n",
    "In this replication study, I will adopt the same methodology proposed in the paper for data selection, cleaning, and preprocessing. I will be using the MIMIC-III and MIMIC-IV datasets and randomly divide the data into training, validation, and test sets as done in the original study. Then I will build the diagnosis graphs and compute the adjacency matrices for their corresponding subgraphs using the same steps as outlined in the paper. Then I will train the model for both diagnosis prediction and heart failure prediction and compare the metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWAHJ_1CdtaA"
   },
   "source": [
    "# Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment\n",
    "- Python Version = 3.9.16\n",
    "- All the necssary python packages are listed in `requirements.txt` file and you can download them by running the command:\n",
    "    \n",
    "    `pip install -r requirements.txt`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NbPHUTMbkD3"
   },
   "source": [
    "### Data\n",
    "\n",
    "#### Source of the data:\n",
    "Currently I am using **MIMIC-III Clinical Database** and **MIMIC-IV Clinical Database**. This data is coming from https://physionet.org/content/mimiciii/1.4/ and https://physionet.org/content/mimiciv/2.2/. The necessary zip files are already downloaded into `data/download/` directory.\n",
    "\n",
    "#### Data process:\n",
    "  1. Inital Data setup: From both the datasets, we just need `admissions.csv`, `diagnosis_icd.csv`, and `patients.csv` data files. I have the download zip files of these located under `data/download/`. And then `inital_data_setup.sh` script can be used to unzip these files into `data/mimic3/raw` and `data/mimic4/raw` directories.\n",
    "  2. Then follow the same data processing steps as in the paper. I have pulled the original scripts for preprocessing from papers repo into the `prepocess` directory. And I am running the `run_preprocess.py` script (copied into the next cell) on the dataset.\n",
    "\n",
    "#### Statistics: \n",
    "The output of the followin script prints out the necessary statistics.\n",
    "  1. MIMIC-III data: There are 7493 patients in total from 2001 to 2012 with max visits of 42 and average visits of 2.6 per patient. The average diagnosis code per visit is 13.06. Using the same configurations as the original paper, we have randomly split the data into training, validation and test set of size 6000, 493 and 1000 respectively. \n",
    "  2. MIMIC-IV data: There are 10000 patients in total from 2013 to 2019 with max visits of 93 and average visits of 3.79 per patient. The  average diagnosis code per visit is 13.51 diagnose codes per visit. Using the same configurations as the original paper, we have randomly split the data into training, validation and test set of size 8000, 1000 and 1000 respectively.\n",
    "\n",
    "Overview of key statistics:\n",
    "\n",
    "  ![image info](assets/dataset_statistics.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is copied from the original code (run_prepocess.py script)\n",
    "# This function also uses some scripts from preprocess module which has also been copied from the source code\n",
    "import os\n",
    "from sys import exit\n",
    "import _pickle as pickle\n",
    "\n",
    "from preprocess import save_sparse, save_data\n",
    "from preprocess.parse_csv import Mimic3Parser, Mimic4Parser, EICUParser\n",
    "from preprocess.encode import encode_code\n",
    "from preprocess.build_dataset import split_patients, build_code_xy, build_heart_failure_y\n",
    "from preprocess.auxiliary import generate_code_code_adjacent, generate_neighbors, normalize_adj, divide_middle, generate_code_levels\n",
    "\n",
    "def run_preprocess_modified(dataset='mimic3', from_saved=True):\n",
    "    conf = {\n",
    "        'mimic3': {\n",
    "            'parser': Mimic3Parser,\n",
    "            'train_num': 6000,\n",
    "            'test_num': 1000,\n",
    "            'threshold': 0.01\n",
    "        },\n",
    "        'mimic4': {\n",
    "            'parser': Mimic4Parser,\n",
    "            'train_num': 8000,\n",
    "            'test_num': 1000,\n",
    "            'threshold': 0.01,\n",
    "            'sample_num': 10000\n",
    "        },\n",
    "        'eicu': {\n",
    "            'parser': EICUParser,\n",
    "            'train_num': 8000,\n",
    "            'test_num': 1000,\n",
    "            'threshold': 0.01\n",
    "        }\n",
    "    }\n",
    "    data_path = 'data'\n",
    "    # dataset = 'mimic3'  # mimic3, eicu, or mimic4\n",
    "    dataset_path = os.path.join(data_path, dataset)\n",
    "    raw_path = os.path.join(dataset_path, 'raw')\n",
    "    if not os.path.exists(raw_path):\n",
    "        os.makedirs(raw_path)\n",
    "        print('please put the CSV files in `data/%s/raw`' % dataset)\n",
    "        exit()\n",
    "    parsed_path = os.path.join(dataset_path, 'parsed')\n",
    "    if from_saved:\n",
    "        patient_admission = pickle.load(open(os.path.join(parsed_path, 'patient_admission.pkl'), 'rb'))\n",
    "        admission_codes = pickle.load(open(os.path.join(parsed_path, 'admission_codes.pkl'), 'rb'))\n",
    "    else:\n",
    "        parser = conf[dataset]['parser'](raw_path)\n",
    "        sample_num = conf[dataset].get('sample_num', None)\n",
    "        patient_admission, admission_codes = parser.parse(sample_num)\n",
    "        print('saving parsed data ...')\n",
    "        if not os.path.exists(parsed_path):\n",
    "            os.makedirs(parsed_path)\n",
    "        pickle.dump(patient_admission, open(os.path.join(parsed_path, 'patient_admission.pkl'), 'wb'))\n",
    "        pickle.dump(admission_codes, open(os.path.join(parsed_path, 'admission_codes.pkl'), 'wb'))\n",
    "\n",
    "    patient_num = len(patient_admission)\n",
    "    max_admission_num = max([len(admissions) for admissions in patient_admission.values()])\n",
    "    avg_admission_num = sum([len(admissions) for admissions in patient_admission.values()]) / patient_num\n",
    "    max_visit_code_num = max([len(codes) for codes in admission_codes.values()])\n",
    "    avg_visit_code_num = sum([len(codes) for codes in admission_codes.values()]) / len(admission_codes)\n",
    "    print('patient num: %d' % patient_num)\n",
    "    print('max admission num: %d' % max_admission_num)\n",
    "    print('mean admission num: %.2f' % avg_admission_num)\n",
    "    print('max code num in an admission: %d' % max_visit_code_num)\n",
    "    print('mean code num in an admission: %.2f' % avg_visit_code_num)\n",
    "\n",
    "    print('encoding code ...')\n",
    "    admission_codes_encoded, code_map = encode_code(patient_admission, admission_codes)\n",
    "    code_num = len(code_map)\n",
    "    print('There are %d codes' % code_num)\n",
    "\n",
    "    code_levels = generate_code_levels(data_path, code_map)\n",
    "    pickle.dump({\n",
    "        'code_levels': code_levels,\n",
    "    }, open(os.path.join(parsed_path, 'code_levels.pkl'), 'wb'))\n",
    "\n",
    "    train_pids, valid_pids, test_pids = split_patients(\n",
    "        patient_admission=patient_admission,\n",
    "        admission_codes=admission_codes,\n",
    "        code_map=code_map,\n",
    "        train_num=conf[dataset]['train_num'],\n",
    "        test_num=conf[dataset]['test_num']\n",
    "    )\n",
    "    print('There are %d train, %d valid, %d test samples' % (len(train_pids), len(valid_pids), len(test_pids)))\n",
    "    code_adj = generate_code_code_adjacent(pids=train_pids, patient_admission=patient_admission,\n",
    "                                           admission_codes_encoded=admission_codes_encoded,\n",
    "                                           code_num=code_num, threshold=conf[dataset]['threshold'])\n",
    "\n",
    "    common_args = [patient_admission, admission_codes_encoded, max_admission_num, code_num]\n",
    "    print('building train codes features and labels ...')\n",
    "    (train_code_x, train_codes_y, train_visit_lens) = build_code_xy(train_pids, *common_args)\n",
    "    print('building valid codes features and labels ...')\n",
    "    (valid_code_x, valid_codes_y, valid_visit_lens) = build_code_xy(valid_pids, *common_args)\n",
    "    print('building test codes features and labels ...')\n",
    "    (test_code_x, test_codes_y, test_visit_lens) = build_code_xy(test_pids, *common_args)\n",
    "\n",
    "    print('generating train neighbors ...')\n",
    "    train_neighbors = generate_neighbors(train_code_x, train_visit_lens, code_adj)\n",
    "    print('generating valid neighbors ...')\n",
    "    valid_neighbors = generate_neighbors(valid_code_x, valid_visit_lens, code_adj)\n",
    "    print('generating test neighbors ...')\n",
    "    test_neighbors = generate_neighbors(test_code_x, test_visit_lens, code_adj)\n",
    "\n",
    "    print('generating train middles ...')\n",
    "    train_divided = divide_middle(train_code_x, train_neighbors, train_visit_lens)\n",
    "    print('generating valid middles ...')\n",
    "    valid_divided = divide_middle(valid_code_x, valid_neighbors, valid_visit_lens)\n",
    "    print('generating test middles ...')\n",
    "    test_divided = divide_middle(test_code_x, test_neighbors, test_visit_lens)\n",
    "\n",
    "    print('building train heart failure labels ...')\n",
    "    train_hf_y = build_heart_failure_y('428', train_codes_y, code_map)\n",
    "    print('building valid heart failure labels ...')\n",
    "    valid_hf_y = build_heart_failure_y('428', valid_codes_y, code_map)\n",
    "    print('building test heart failure labels ...')\n",
    "    test_hf_y = build_heart_failure_y('428', test_codes_y, code_map)\n",
    "\n",
    "    encoded_path = os.path.join(dataset_path, 'encoded')\n",
    "    if not os.path.exists(encoded_path):\n",
    "        os.makedirs(encoded_path)\n",
    "    print('saving encoded data ...')\n",
    "    pickle.dump(patient_admission, open(os.path.join(encoded_path, 'patient_admission.pkl'), 'wb'))\n",
    "    pickle.dump(admission_codes_encoded, open(os.path.join(encoded_path, 'codes_encoded.pkl'), 'wb'))\n",
    "    pickle.dump(code_map, open(os.path.join(encoded_path, 'code_map.pkl'), 'wb'))\n",
    "    pickle.dump({\n",
    "        'train_pids': train_pids,\n",
    "        'valid_pids': valid_pids,\n",
    "        'test_pids': test_pids\n",
    "    }, open(os.path.join(encoded_path, 'pids.pkl'), 'wb'))\n",
    "\n",
    "    print('saving standard data ...')\n",
    "    standard_path = os.path.join(dataset_path, 'standard')\n",
    "    train_path = os.path.join(standard_path, 'train')\n",
    "    valid_path = os.path.join(standard_path, 'valid')\n",
    "    test_path = os.path.join(standard_path, 'test')\n",
    "    if not os.path.exists(standard_path):\n",
    "        os.makedirs(standard_path)\n",
    "    if not os.path.exists(train_path):\n",
    "        os.makedirs(train_path)\n",
    "        os.makedirs(valid_path)\n",
    "        os.makedirs(test_path)\n",
    "\n",
    "    print('\\tsaving training data')\n",
    "    save_data(train_path, train_code_x, train_visit_lens, train_codes_y, train_hf_y, train_divided, train_neighbors)\n",
    "    print('\\tsaving valid data')\n",
    "    save_data(valid_path, valid_code_x, valid_visit_lens, valid_codes_y, valid_hf_y, valid_divided, valid_neighbors)\n",
    "    print('\\tsaving test data')\n",
    "    save_data(test_path, test_code_x, test_visit_lens, test_codes_y, test_hf_y, test_divided, test_neighbors)\n",
    "\n",
    "    code_adj = normalize_adj(code_adj)\n",
    "    save_sparse(os.path.join(standard_path, 'code_adj'), code_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing the csv file of admission ...\n",
      "\t58976 in 58976 rows\n",
      "parsing csv file of diagnosis ...\n",
      "\t651047 in 651047 rows\n",
      "calibrating patients by admission ...\n",
      "calibrating admission by patients ...\n",
      "saving parsed data ...\n",
      "patient num: 7493\n",
      "max admission num: 42\n",
      "mean admission num: 2.66\n",
      "max code num in an admission: 39\n",
      "mean code num in an admission: 13.06\n",
      "encoding code ...\n",
      "There are 4880 codes\n",
      "generating code levels ...\n",
      "\t100%00%\n",
      "There are 6000 train, 493 valid, 1000 test samples\n",
      "generating code code adjacent matrix ...\n",
      "\t6000 / 6000\n",
      "building train codes features and labels ...\n",
      "\t6000 / 6000\n",
      "building valid codes features and labels ...\n",
      "\t493 / 493\n",
      "building test codes features and labels ...\n",
      "\t1000 / 1000\n",
      "generating train neighbors ...\n",
      "\t6000 / 6000\n",
      "generating valid neighbors ...\n",
      "\t493 / 493\n",
      "generating test neighbors ...\n",
      "\t1000 / 1000\n",
      "generating train middles ...\n",
      "\t6000 / 6000\n",
      "generating valid middles ...\n",
      "\t493 / 493\n",
      "generating test middles ...\n",
      "\t1000 / 1000\n",
      "building train heart failure labels ...\n",
      "building valid heart failure labels ...\n",
      "building test heart failure labels ...\n",
      "saving encoded data ...\n",
      "saving standard data ...\n",
      "\tsaving training data\n",
      "\tsaving valid data\n",
      "\tsaving test data\n"
     ]
    }
   ],
   "source": [
    "run_preprocess_modified(dataset='mimic3', from_saved=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ICD-10 to ICD-9 map ...\n",
      "loading patients anchor year ...\n",
      "parsing the csv file of admission ...\n",
      "\tselecting valid admission ...\n",
      "\t\t431231 in 431231 rows\n",
      "\t\tremaining 221815 rows\n",
      "\t221815 in 221815 rows\n",
      "parsing csv file of diagnosis ...\n",
      "\tmapping ICD-10 to ICD-9 ...\n",
      "\t\t4756326 in 4756326 rows\n",
      "\t4756326 in 4756326 rows\n",
      "calibrating patients by admission ...\n",
      "calibrating admission by patients ...\n",
      "saving parsed data ...\n",
      "patient num: 10000\n",
      "max admission num: 93\n",
      "mean admission num: 3.79\n",
      "max code num in an admission: 39\n",
      "mean code num in an admission: 13.51\n",
      "encoding code ...\n",
      "There are 5985 codes\n",
      "generating code levels ...\n",
      "\t100%00%\n",
      "There are 8000 train, 1000 valid, 1000 test samples\n",
      "generating code code adjacent matrix ...\n",
      "\t8000 / 8000\n",
      "building train codes features and labels ...\n",
      "\t8000 / 8000\n",
      "building valid codes features and labels ...\n",
      "\t1000 / 1000\n",
      "building test codes features and labels ...\n",
      "\t1000 / 1000\n",
      "generating train neighbors ...\n",
      "\t8000 / 8000\n",
      "generating valid neighbors ...\n",
      "\t1000 / 1000\n",
      "generating test neighbors ...\n",
      "\t1000 / 1000\n",
      "generating train middles ...\n",
      "\t8000 / 8000\n",
      "generating valid middles ...\n",
      "\t1000 / 1000\n",
      "generating test middles ...\n",
      "\t1000 / 1000\n",
      "building train heart failure labels ...\n",
      "building valid heart failure labels ...\n",
      "building test heart failure labels ...\n",
      "saving encoded data ...\n",
      "saving standard data ...\n",
      "\tsaving training data\n",
      "\tsaving valid data\n",
      "\tsaving test data\n"
     ]
    }
   ],
   "source": [
    "run_preprocess_modified(dataset='mimic4', from_saved=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3muyDPFPbozY"
   },
   "source": [
    "### Model\n",
    "The model classes and functions have been pulled from the papers original code\n",
    "\n",
    "1. Citation to paper: Lu, C., Han, T., & Ning, Y. (2022). Context-Aware Health Event Prediction via Transition Functions on Dynamic Disease Graphs. Proceedings of the AAAI Conference on Artificial Intelligence, 36(4), 4567-4574. https://doi.org/10.1609/aaai.v36i4.20380\n",
    "\n",
    "2. Citation to paper's repo: Lu, Chang. “LuChang-CS/Chet.” GitHub, 16 Dec. 2023, github.com/LuChang-CS/Chet. Accessed 8 May 2024.\n",
    "   - link to repo: https://github.com/LuChang-CS/Chet\n",
    "\n",
    "#### Model Overview\n",
    "The Chet model can be made up of three layers: graph layer, transition layer and embedding layer. I will explain each of the layers below along with their implementation code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch import nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Graph Layer\n",
    "This is the Optimized dynamic graph layer which extracts both local and global contexts for diagnoses and neighbors in visit t and then calculate hidden embeddings for diagnoses and neighbors. This is acchieved by the following memory-efficient calculations:\n",
    "- `ZDt = m^t ⊙ (M +A(m^t ⊙ M) + A(n^t ⊙ N))`  --> aggregated diagnosis local and global context\n",
    "- `ZNt = n^t ⊙ (N +A(n^t ⊙ N) + A(m^t ⊙ M))`  --> aggregated neighbor global context\n",
    "\n",
    "where M,N represent embedding matrices of diseases for diagnoses and neighbors respectively, A is the static adjacency matrix, m^t and n^t represent diagnoses and neighbors code in t visit.\n",
    "\n",
    "The GNN outputs are calculated with a fully connected layer using LeakyReLU as the activation function:\n",
    "- `Ht = LeakyReLU(Zt * W) ∈ R^(d×s)′`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphLayer(nn.Module):\n",
    "    def __init__(self, adj, code_size, graph_size):\n",
    "        super().__init__()\n",
    "        self.adj = adj\n",
    "        self.dense = nn.Linear(code_size, graph_size)\n",
    "        self.activation = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, code_x, neighbor, c_embeddings, n_embeddings):\n",
    "        center_codes = torch.unsqueeze(code_x, dim=-1)\n",
    "        neighbor_codes = torch.unsqueeze(neighbor, dim=-1)\n",
    "\n",
    "        center_embeddings = center_codes * c_embeddings\n",
    "        neighbor_embeddings = neighbor_codes * n_embeddings\n",
    "        cc_embeddings = center_codes * torch.matmul(self.adj, center_embeddings)\n",
    "        cn_embeddings = center_codes * torch.matmul(self.adj, neighbor_embeddings)\n",
    "        nn_embeddings = neighbor_codes * torch.matmul(self.adj, neighbor_embeddings)\n",
    "        nc_embeddings = neighbor_codes * torch.matmul(self.adj, center_embeddings)\n",
    "\n",
    "        co_embeddings = self.activation(self.dense(center_embeddings + cc_embeddings + cn_embeddings))\n",
    "        no_embeddings = self.activation(self.dense(neighbor_embeddings + nn_embeddings + nc_embeddings))\n",
    "        return co_embeddings, no_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Transition Layer \n",
    "This is the transition functions layer which takes the hidden embeddings from the graph layer as inputs to this layer and applies GRU, M-GRU, or attention functions to learn the disease development schemes. \n",
    "\n",
    "This layer takes `m^t` (vector of diagnosis codes) and divided it into three disjoint parts to represent longstanding and new-onset diseases:\n",
    "    1. Persistent diseases: represents diagnoses in visit `t` that are also diagnoses in visit `t − 1`\n",
    "    2. Emerging neighbors: represents diagnoses in visit `t` that are neighbors in visit `t − 1`\n",
    "    3. Emerging unrelated diseases: represents diagnoses in visit `t` that are unrelated diseases in visit `t − 1`\n",
    "Using these three parts of `m^t` with three transition functions for each part, historical contect is extracted from previous visits.\n",
    "\n",
    "Then a modified gated recurrent unit (M-GRU) is used to model continuous features, that is to calculate the hidden values of `m^tp` (persistent diseases) to output `h^tp`\n",
    "\n",
    "Lastly, max pooling is applied to the transistion output of the three partitoins to calculate the visit embedding `v^t`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, query_size, key_size, value_size, attention_size):\n",
    "        super().__init__()\n",
    "        self.attention_size = attention_size\n",
    "        self.dense_q = nn.Linear(query_size, attention_size)\n",
    "        self.dense_k = nn.Linear(key_size, attention_size)\n",
    "        self.dense_v = nn.Linear(query_size, value_size)\n",
    "\n",
    "    def forward(self, q, k, v):\n",
    "        query = self.dense_q(q)\n",
    "        key = self.dense_k(k)\n",
    "        value = self.dense_v(v)\n",
    "        g = torch.div(torch.matmul(query, key.T), math.sqrt(self.attention_size))\n",
    "        score = torch.softmax(g, dim=-1)\n",
    "        output = torch.sum(torch.unsqueeze(score, dim=-1) * value, dim=-2)\n",
    "        return output\n",
    "\n",
    "\n",
    "class TransitionLayer(nn.Module):\n",
    "    def __init__(self, code_num, graph_size, hidden_size, t_attention_size, t_output_size):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRUCell(input_size=graph_size, hidden_size=hidden_size)\n",
    "        self.single_head_attention = SingleHeadAttentionLayer(graph_size, graph_size, t_output_size, t_attention_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        self.code_num = code_num\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, t, co_embeddings, divided, no_embeddings, unrelated_embeddings, hidden_state=None):\n",
    "        m1, m2, m3 = divided[:, 0], divided[:, 1], divided[:, 2]\n",
    "        m1_index = torch.where(m1 > 0)[0]\n",
    "        m2_index = torch.where(m2 > 0)[0]\n",
    "        m3_index = torch.where(m3 > 0)[0]\n",
    "        h_new = torch.zeros((self.code_num, self.hidden_size), dtype=co_embeddings.dtype).to(co_embeddings.device)\n",
    "        output_m1 = 0\n",
    "        output_m23 = 0\n",
    "        if len(m1_index) > 0:\n",
    "            m1_embedding = co_embeddings[m1_index]\n",
    "            h = hidden_state[m1_index] if hidden_state is not None else None\n",
    "            h_m1 = self.gru(m1_embedding, h)\n",
    "            h_new[m1_index] = h_m1\n",
    "            output_m1, _ = torch.max(h_m1, dim=-2)\n",
    "        if t > 0 and len(m2_index) + len(m3_index) > 0:\n",
    "            q = torch.vstack([no_embeddings[m2_index], unrelated_embeddings[m3_index]])\n",
    "            v = torch.vstack([co_embeddings[m2_index], co_embeddings[m3_index]])\n",
    "            h_m23 = self.activation(self.single_head_attention(q, q, v))\n",
    "            h_new[m2_index] = h_m23[:len(m2_index)]\n",
    "            h_new[m3_index] = h_m23[len(m2_index):]\n",
    "            output_m23, _ = torch.max(h_m23, dim=-2)\n",
    "        if len(m1_index) == 0:\n",
    "            output = output_m23\n",
    "        elif len(m2_index) + len(m3_index) == 0:\n",
    "            output = output_m1\n",
    "        else:\n",
    "            output, _ = torch.max(torch.vstack([output_m1, output_m23]), dim=-2)\n",
    "        return output, h_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Embedding Layer\n",
    "\n",
    "The embedding layer applies a location-based attention to calculate the final hidden representation of all visits embeddings. And the patient embedding `o` will be used in a classifier for final predictions of a specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(self, code_num, code_size, graph_size):\n",
    "        super().__init__()\n",
    "        self.code_num = code_num\n",
    "        self.c_embeddings = nn.Parameter(data=nn.init.xavier_uniform_(torch.empty(code_num, code_size)))\n",
    "        self.n_embeddings = nn.Parameter(data=nn.init.xavier_uniform_(torch.empty(code_num, code_size)))\n",
    "        self.u_embeddings = nn.Parameter(data=nn.init.xavier_uniform_(torch.empty(code_num, graph_size)))\n",
    "\n",
    "    def forward(self):\n",
    "        return self.c_embeddings, self.n_embeddings, self.u_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Classifier and Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(nn.Module):\n",
    "    def __init__(self, value_size, attention_size):\n",
    "        super().__init__()\n",
    "        self.attention_size = attention_size\n",
    "        self.context = nn.Parameter(data=nn.init.xavier_uniform_(torch.empty(attention_size, 1)))\n",
    "        self.dense = nn.Linear(value_size, attention_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        t = self.dense(x)\n",
    "        vu = torch.matmul(t, self.context).squeeze()\n",
    "        score = torch.softmax(vu, dim=-1)\n",
    "        output = torch.sum(x * torch.unsqueeze(score, dim=-1), dim=-2)\n",
    "        return output\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, output_size, dropout_rate=0., activation=None):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        self.activation = activation\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.dropout(x)\n",
    "        output = self.linear(output)\n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, code_num, code_size,\n",
    "                 adj, graph_size, hidden_size, t_attention_size, t_output_size,\n",
    "                 output_size, dropout_rate, activation):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = EmbeddingLayer(code_num, code_size, graph_size)\n",
    "        self.graph_layer = GraphLayer(adj, code_size, graph_size)\n",
    "        self.transition_layer = TransitionLayer(code_num, graph_size, hidden_size, t_attention_size, t_output_size)\n",
    "        self.attention = DotProductAttention(hidden_size, 32)\n",
    "        self.classifier = Classifier(hidden_size, output_size, dropout_rate, activation)\n",
    "\n",
    "    def forward(self, code_x, divided, neighbors, lens):\n",
    "        embeddings = self.embedding_layer()\n",
    "        c_embeddings, n_embeddings, u_embeddings = embeddings\n",
    "        output = []\n",
    "        for code_x_i, divided_i, neighbor_i, len_i in zip(code_x, divided, neighbors, lens):\n",
    "            no_embeddings_i_prev = None\n",
    "            output_i = []\n",
    "            h_t = None\n",
    "            for t, (c_it, d_it, n_it, len_it) in enumerate(zip(code_x_i, divided_i, neighbor_i, range(len_i))):\n",
    "                co_embeddings, no_embeddings = self.graph_layer(c_it, n_it, c_embeddings, n_embeddings)\n",
    "                output_it, h_t = self.transition_layer(t, co_embeddings, d_it, no_embeddings_i_prev, u_embeddings, h_t)\n",
    "                no_embeddings_i_prev = no_embeddings\n",
    "                output_i.append(output_it)\n",
    "            output_i = self.attention(torch.vstack(output_i))\n",
    "            output.append(output_i)\n",
    "        output = torch.vstack(output)\n",
    "        output = self.classifier(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "#### Hyperparams\n",
    "Most of the hyperparameters are kept the same as from the original paper:\n",
    "- hidden_size = 150\n",
    "- batch_size = 32\n",
    "- dropout_rate = 0.45 (for diagnosis prediction)\n",
    "- dropout_rate = 0.0 (for heart failure prediction)\n",
    "\n",
    "The only parameter that have been modified are epochs and learning rate. I decreased the epochs from 200 to 20 and 10. \n",
    "And adjusted the learing rates accordingly with inital one starting at 0.01 for epoch 0.01:\n",
    "- lrs: [1e-3, 1e-5] (for diagnosis prediction)\n",
    "- lrs: [1e-3, 1e-4, 1e-5] (for heart failure prediction)\n",
    "\n",
    "### Computational requirements\n",
    "1. All of the code is in python and uses pytorch packages.\n",
    "2. Model was ran on my local computer with the specs: 32GB memory, Apple M2 Pro chip, 12 CPUs.\n",
    "    - For training both mimic3 and mimic4 datasets for both diagnosis and heart failure tasks:\n",
    "        - It took about 30 minutes for each epoch \n",
    "        - Ran it for 20 epochs for a total run time of about 10 hours\n",
    "3. As test to check performace of GPU, I ran it in Google Colab with their standard GPUs on just mimic3 data:\n",
    "    - took about 6 minutes per epoch\n",
    "    - Ran for 20 epochs for total run time of about 1 hour\n",
    "So clearly the use of GPUs will help improve runtime significantly compared to running on CPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_adj, EHRDataset, format_time, MultiStepLRScheduler\n",
    "from metrics import evaluate_codes, evaluate_hf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulled these hyperparameters from source code (train.py)\n",
    "code_size = 48\n",
    "graph_size = 32\n",
    "hidden_size = 150  # rnn hidden size\n",
    "t_attention_size = 32\n",
    "t_output_size = hidden_size\n",
    "batch_size = 32\n",
    "epochs = 20  # 200  # decreased this to just 10 for testing purposes\n",
    "\n",
    "seed = 6669\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "use_cuda = False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() and use_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train data ...\n",
      "loading valid data ...\n",
      "loading test data ...\n"
     ]
    }
   ],
   "source": [
    "# Loading the data\n",
    "dataset = 'mimic3'\n",
    "task = 'm'\n",
    "\n",
    "dataset_path = os.path.join('data', dataset, 'standard')\n",
    "train_path = os.path.join(dataset_path, 'train')\n",
    "valid_path = os.path.join(dataset_path, 'valid')\n",
    "test_path = os.path.join(dataset_path, 'test')\n",
    "\n",
    "code_adj = load_adj(dataset_path, device=device)\n",
    "code_num = len(code_adj)\n",
    "print('loading train data ...')\n",
    "train_data = EHRDataset(train_path, label=task, batch_size=batch_size, shuffle=True, device=device)\n",
    "print('loading valid data ...')\n",
    "valid_data = EHRDataset(valid_path, label=task, batch_size=batch_size, shuffle=False, device=device)\n",
    "print('loading test data ...')\n",
    "test_data = EHRDataset(test_path, label=task, batch_size=batch_size, shuffle=False, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def historical_hot(code_x, code_num, lens):\n",
    "    result = np.zeros((len(code_x), code_num), dtype=int)\n",
    "    for i, (x, l) in enumerate(zip(code_x, lens)):\n",
    "        result[i] = x[l - 1]\n",
    "    return result\n",
    "    \n",
    "task_conf = {\n",
    "    'm': {\n",
    "        'dropout': 0.45,\n",
    "        'output_size': code_num,\n",
    "        'evaluate_fn': evaluate_codes,\n",
    "        'lr': {\n",
    "            'init_lr': 0.01,\n",
    "            'milestones': [15, 17],\n",
    "            'lrs': [1e-3, 1e-5]\n",
    "        }\n",
    "    },\n",
    "    'h': {\n",
    "        'dropout': 0.0,\n",
    "        'output_size': 1,\n",
    "        'evaluate_fn': evaluate_hf,\n",
    "        'lr': {\n",
    "            'init_lr': 0.01,\n",
    "            'milestones': [2,3,4],\n",
    "            'lrs': [1e-3, 1e-4, 1e-5]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1457814\n",
      "Epoch 1 / 20:\n",
      "    Step 188 / 188, time cost: 5m4.2s, loss: 183.6746746216\n",
      "    Evaluation: loss: 64.9205 --- f1_score: 0.1089 --- top_k_recall: 0.1904, 0.2642, 0.3204, 0.3684  --- occurred: 0.0969, 0.1207, 0.1390, 0.1584  --- not occurred: 0.0935, 0.1435, 0.1814, 0.2101\n",
      "Epoch 2 / 20:\n",
      "    Step 188 / 188, time cost: 5m5.1s, loss: 70.0944944003\n",
      "    Evaluation: loss: 64.5806 --- f1_score: 0.1100 --- top_k_recall: 0.1895, 0.2645, 0.3253, 0.3763  --- occurred: 0.1011, 0.1273, 0.1442, 0.1598  --- not occurred: 0.0884, 0.1372, 0.1811, 0.2165\n",
      "Epoch 3 / 20:\n",
      "    Step 188 / 188, time cost: 5m10.6s, loss: 69.234545607\n",
      "    Evaluation: loss: 64.1175 --- f1_score: 0.1124 --- top_k_recall: 0.1928, 0.2741, 0.3274, 0.3736  --- occurred: 0.0967, 0.1245, 0.1432, 0.1580  --- not occurred: 0.0961, 0.1496, 0.1842, 0.2156\n",
      "Epoch 4 / 20:\n",
      "    Step 188 / 188, time cost: 5m9.1s, loss: 68.1644644749\n",
      "    Evaluation: loss: 63.9361 --- f1_score: 0.1150 --- top_k_recall: 0.2042, 0.2841, 0.3410, 0.3828  --- occurred: 0.0998, 0.1295, 0.1492, 0.1615  --- not occurred: 0.1044, 0.1546, 0.1918, 0.2213\n",
      "Epoch 5 / 20:\n",
      "    Step 188 / 188, time cost: 5m9.4s, loss: 67.3096096907\n",
      "    Evaluation: loss: 62.7383 --- f1_score: 0.1282 --- top_k_recall: 0.1980, 0.2923, 0.3519, 0.3977  --- occurred: 0.0999, 0.1315, 0.1523, 0.1672  --- not occurred: 0.0981, 0.1608, 0.1996, 0.2305\n",
      "Epoch 6 / 20:\n",
      "    Step 183 / 188, remaining time: 8.4s, loss: 66.2807422"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     35\u001b[0m code_x, visit_lens, divided, y, neighbors \u001b[38;5;241m=\u001b[39m train_data[step]\n\u001b[0;32m---> 36\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdivided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisit_lens\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     37\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(output, y)\n\u001b[1;32m     38\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Desktop/uiuc/598-DeepLearningForHealthcare/Project/cs598-dlh-project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/uiuc/598-DeepLearningForHealthcare/Project/cs598-dlh-project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 51\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, code_x, divided, neighbors, lens)\u001b[0m\n\u001b[1;32m     49\u001b[0m h_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t, (c_it, d_it, n_it, len_it) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(code_x_i, divided_i, neighbor_i, \u001b[38;5;28mrange\u001b[39m(len_i))):\n\u001b[0;32m---> 51\u001b[0m     co_embeddings, no_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_it\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_it\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     output_it, h_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransition_layer(t, co_embeddings, d_it, no_embeddings_i_prev, u_embeddings, h_t)\n\u001b[1;32m     53\u001b[0m     no_embeddings_i_prev \u001b[38;5;241m=\u001b[39m no_embeddings\n",
      "File \u001b[0;32m~/Desktop/uiuc/598-DeepLearningForHealthcare/Project/cs598-dlh-project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/uiuc/598-DeepLearningForHealthcare/Project/cs598-dlh-project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 17\u001b[0m, in \u001b[0;36mGraphLayer.forward\u001b[0;34m(self, code_x, neighbor, c_embeddings, n_embeddings)\u001b[0m\n\u001b[1;32m     15\u001b[0m cn_embeddings \u001b[38;5;241m=\u001b[39m center_codes \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madj, neighbor_embeddings)\n\u001b[1;32m     16\u001b[0m nn_embeddings \u001b[38;5;241m=\u001b[39m neighbor_codes \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madj, neighbor_embeddings)\n\u001b[0;32m---> 17\u001b[0m nc_embeddings \u001b[38;5;241m=\u001b[39m neighbor_codes \u001b[38;5;241m*\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m co_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(center_embeddings \u001b[38;5;241m+\u001b[39m cc_embeddings \u001b[38;5;241m+\u001b[39m cn_embeddings))\n\u001b[1;32m     20\u001b[0m no_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(neighbor_embeddings \u001b[38;5;241m+\u001b[39m nn_embeddings \u001b[38;5;241m+\u001b[39m nc_embeddings))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "test_historical = historical_hot(valid_data.code_x, code_num, valid_data.visit_lens)\n",
    "\n",
    "output_size = task_conf[task]['output_size']\n",
    "activation = torch.nn.Sigmoid()\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "evaluate_fn = task_conf[task]['evaluate_fn']\n",
    "dropout_rate = task_conf[task]['dropout']\n",
    "\n",
    "param_path = os.path.join('data', 'params', dataset, task)\n",
    "if not os.path.exists(param_path):\n",
    "    os.makedirs(param_path)\n",
    "\n",
    "model = Model(code_num=code_num, code_size=code_size,\n",
    "                adj=code_adj, graph_size=graph_size, hidden_size=hidden_size, t_attention_size=t_attention_size,\n",
    "                t_output_size=t_output_size,\n",
    "                output_size=output_size, dropout_rate=dropout_rate, activation=activation).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = MultiStepLRScheduler(optimizer, epochs, task_conf[task]['lr']['init_lr'],\n",
    "                                    task_conf[task]['lr']['milestones'], task_conf[task]['lr']['lrs'])\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(pytorch_total_params)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Epoch %d / %d:' % (epoch + 1, epochs))\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_num = 0\n",
    "    steps = len(train_data)\n",
    "    st = time.time()\n",
    "    scheduler.step()\n",
    "    for step in range(len(train_data)):\n",
    "        optimizer.zero_grad()\n",
    "        code_x, visit_lens, divided, y, neighbors = train_data[step]\n",
    "        output = model(code_x, divided, neighbors, visit_lens).squeeze()\n",
    "        loss = loss_fn(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * output_size * len(code_x)\n",
    "        total_num += len(code_x)\n",
    "\n",
    "        end_time = time.time()\n",
    "        remaining_time = format_time((end_time - st) / (step + 1) * (steps - step - 1))\n",
    "        print('\\r    Step %d / %d, remaining time: %s, loss: %.4f'\n",
    "                % (step + 1, steps, remaining_time, total_loss / total_num), end='')\n",
    "    train_data.on_epoch_end()\n",
    "    et = time.time()\n",
    "    time_cost = format_time(et - st)\n",
    "    print('\\r    Step %d / %d, time cost: %s, loss: %.4f' % (steps, steps, time_cost, total_loss / total_num))\n",
    "    valid_loss, f1_score = evaluate_fn(model, valid_data, loss_fn, output_size, test_historical)\n",
    "    torch.save(model.state_dict(), os.path.join(param_path, '%d.pt' % epoch))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8EAWAy_LwHlV"
   },
   "source": [
    "## Results\n",
    "\n",
    "I have the results under `results/` in text files.\n",
    "\n",
    "The models were evaluated against the test datasets and the results are coming from training each of the Chet models with 20 epochs instead of 200 epochs (as suggested in the paper). The performace of the model did align with the data presented in the paper for both the diagnosis and heart failure tasks. \n",
    "\n",
    "For heart failure:\n",
    "- MIMIC-III:\n",
    "    - Paper results:\n",
    "        - F1 score: 73.08\n",
    "        - AUC: 86.14\n",
    "    - My results:\n",
    "        - F1 score: 72.00\n",
    "        - AUC: 85.56\n",
    "- MIMIC-IV:\n",
    "    - Paper results:\n",
    "        - F1 score: 71.14\n",
    "        - AUC: 90.83\n",
    "    - My results:\n",
    "        - F1 score: 74.45\n",
    "        - AUC: 93.25\n",
    "As we can see, my results in terms of F1 score and AUC are very close to those presented in the paper even though these are based on just 20 epochs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qH75TNU71eRH"
   },
   "source": [
    "# Discussion\n",
    "\n",
    "The paper was reproducible. For this, I was able to download data MIMIC-III and MIMIC-IV data from https://physionet.org/. And then for the rest, from data processing to model building to model training and metrics evaluation, I was able to use the original papers code from https://github.com/LuChang-CS/Chet/tree/master. After looking at the performance of the model against the test dataset, the results align with the those from the paper for the heart failure prediction and diagnosis prediction task despite training the model on just 5 epoches instance of 200 recommended by the paper. \n",
    "\n",
    "It was really easy to replicate the whole process mentioned in the paper because they provided the source code. But it was a little difficult to get the data. I initally used the MIMIC-III demo dataset which ended up not giving any results as the dataset was too small. So I highly suggest getting access to the full dataset before reproducing the Chet model. Also the model takes a long time to run so it was difficult to run with 200 epoches so instead I only ran 20 epoches. But even with this difference the model results were were compariable to the data presented in the paper.\n",
    "\n",
    "**What was easy:**\n",
    "1. MIMIC data is easily avaliable as long as you complete the process to get access to it\n",
    "2. The original code base is easy to follow and reproduce.\n",
    "\n",
    "**What was difficult:**\n",
    "1. The biggest difficult is training the model due to computational requirements. On cpus, the models run for hours where as with GPUs it is significantly faster but avaliability and cost of GPUs is limiting.\n",
    "2. The baseline model (CGL) was hard to repoduce and I was never able to get it to run. It seems to require some manual adjustments with the data processing as well as with the models adjacency graph.\n",
    "\n",
    "**Recommendations**\n",
    "1. It would be nice if there were more comments within the code for better readability. Also providing some refrences within the code to the equations in the paper would help with understanding the translation between the paper and code.\n",
    "2. I think mode details on data preprocessing would be helpful in understanding how the data is actually be prepped for the models. I blindly just used the provided code but it would be good to get a better understanding of what is being done to the data.\n",
    "3. Providing a small set of data with different hyperparamters for testing the model would be nice. Due to the computational requirements it is hard to test the model. So having that small dataset would help people play around with the model a bit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHMI2chl9omn"
   },
   "source": [
    "# References\n",
    "1. Lu, C., Han, T., & Ning, Y. (2022). Context-Aware Health Event Prediction via Transition Functions on Dynamic Disease Graphs. Proceedings of the AAAI Conference on Artificial Intelligence, 36(4), 4567-4574. https://doi.org/10.1609/aaai.v36i4.20380\n",
    "2. Johnson, Alistair, et al. \"MIMIC-IV\" (version 2.2). PhysioNet (2023), https://doi.org/10.13026/6mm1-ek67.\n",
    "3. Johnson, A., Pollard, T., & Mark, R. (2019). MIMIC-III Clinical Database Demo (version 1.4). PhysioNet. https://doi.org/10.13026/C2HM2Q.\n",
    "4. Lu, Chang. “LuChang-CS/Chet.” GitHub, 16 Dec. 2023, github.com/LuChang-CS/Chet. Accessed 8 May 2024.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
